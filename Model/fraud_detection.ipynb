{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04fd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data handling\n",
    "import pandas as pd\n",
    "# Import StandardScaler for feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import SMOTE to handle imbalanced dataset by oversampling minority class\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3acae35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the credit card fraud dataset from CSV file\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccde213e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b122ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total missing values per column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06948b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('Class', axis=1)  # Drop the 'Class' column which is the label\n",
    "y = df['Class']               # 'Class' column indicates fraud (1) or legitimate (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2246fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (284807, 31)\n",
      "Class distribution:\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print dataset shape and distribution of classes to understand imbalance\n",
    "print(f\"Dataset loaded. Shape: {df.shape}\")\n",
    "print(\"Class distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf9df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale feature values using StandardScaler to normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1147e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE, class distribution: Class\n",
      "0    284315\n",
      "1    284315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use SMOTE to create synthetic samples for minority class to balance dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Print new class distribution after SMOTE oversampling\n",
    "print(f\"After SMOTE, class distribution: {pd.Series(y_resampled).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed252339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split to split dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import various classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b6345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split resampled data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488737de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 5 different models to compare performance\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42),\n",
    "    # 'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7a0c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Training Gradient Boosting...\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ch Hassan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "All models trained.\n"
     ]
    }
   ],
   "source": [
    "# Train each model on the training data\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "print(\"All models trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b126dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import metrics to evaluate model performance\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Variables to keep track of the best model\n",
    "best_f1 = 0\n",
    "best_model_name = None\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbd0dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Evaluation ---\n",
      "Precision: 0.9998\n",
      "Recall:    1.0000\n",
      "F1-Score:  0.9999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56750\n",
      "           1       1.00      1.00      1.00     56976\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "\n",
      "--- Gradient Boosting Evaluation ---\n",
      "Precision: 0.9860\n",
      "Recall:    0.9697\n",
      "F1-Score:  0.9778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     56750\n",
      "           1       0.99      0.97      0.98     56976\n",
      "\n",
      "    accuracy                           0.98    113726\n",
      "   macro avg       0.98      0.98      0.98    113726\n",
      "weighted avg       0.98      0.98      0.98    113726\n",
      "\n",
      "\n",
      "--- AdaBoost Evaluation ---\n",
      "Precision: 0.9825\n",
      "Recall:    0.9661\n",
      "F1-Score:  0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     56750\n",
      "           1       0.98      0.97      0.97     56976\n",
      "\n",
      "    accuracy                           0.97    113726\n",
      "   macro avg       0.97      0.97      0.97    113726\n",
      "weighted avg       0.97      0.97      0.97    113726\n",
      "\n",
      "\n",
      "--- Logistic Regression Evaluation ---\n",
      "Precision: 0.9743\n",
      "Recall:    0.9247\n",
      "F1-Score:  0.9489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     56750\n",
      "           1       0.97      0.92      0.95     56976\n",
      "\n",
      "    accuracy                           0.95    113726\n",
      "   macro avg       0.95      0.95      0.95    113726\n",
      "weighted avg       0.95      0.95      0.95    113726\n",
      "\n",
      "\n",
      "Best model selected: Random Forest with F1-score = 0.9999\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model using precision, recall, and F1-score\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)  # Make predictions on test set\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)  # How many detected frauds are correct\n",
    "    recall = recall_score(y_test, y_pred)        # How many actual frauds were detected\n",
    "    f1 = f1_score(y_test, y_pred)                # Harmonic mean of precision and recall\n",
    "\n",
    "    print(f\"\\n--- {name} Evaluation ---\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(classification_report(y_test, y_pred)) # Detailed classification metrics\n",
    "\n",
    "    # Update the best model if this model has higher F1-score\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model_name = name\n",
    "        best_model = model\n",
    "\n",
    "# Print the name and F1-score of the best performing model\n",
    "print(f\"\\nBest model selected: {best_model_name} with F1-score = {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de934c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_transaction(model, scaler, feature_names):\n",
    "    # Hardcoded example input for all 30 features: Time + V1 to V28 + Amount\n",
    "    hardcoded_input = [\n",
    "        0.0,                      # Time\n",
    "        -1.3598071336738,         # V1\n",
    "        -0.0727811733098497,      # V2\n",
    "        2.53634673796914,         # V3\n",
    "        1.37815522427443,         # V4\n",
    "        -0.338320769942518,       # V5\n",
    "        0.462387777762292,        # V6\n",
    "        0.239598554061257,        # V7\n",
    "        0.0986979012610507,       # V8\n",
    "        0.363786969611213,        # V9\n",
    "        0.0907941719789316,       # V10\n",
    "        -0.551599533260813,       # V11\n",
    "        -0.617800855762348,       # V12\n",
    "        -0.991389847235408,       # V13\n",
    "        -0.311169353699879,       # V14\n",
    "        1.46817697209427,         # V15\n",
    "        -0.470400525259478,       # V16\n",
    "        0.207971241929242,        # V17\n",
    "        0.0257905801985591,       # V18\n",
    "        0.403992960255733,        # V19\n",
    "        0.251412098239705,        # V20\n",
    "        -0.018306777944153,       # V21\n",
    "        0.277837575558899,        # V22\n",
    "        -0.110473910188767,       # V23\n",
    "        0.0669280749146731,       # V24\n",
    "        0.128539358273528,        # V25\n",
    "        -0.189114843888824,       # V26\n",
    "        0.133558376740387,        # V27\n",
    "        -0.0210530534538215,      # V28\n",
    "        149.62                    # Amount\n",
    "    ]\n",
    "\n",
    "    print(\"\\nUsing hardcoded transaction data for prediction...\")\n",
    "\n",
    "    # Convert hardcoded input to numpy array and scale features\n",
    "    input_array = np.array(hardcoded_input).reshape(1, -1)\n",
    "    input_scaled = scaler.transform(input_array)\n",
    "\n",
    "    # Predict fraud or not using the best model\n",
    "    prediction = model.predict(input_scaled)[0]\n",
    "\n",
    "    # Output prediction result\n",
    "    if prediction == 1:\n",
    "        print(\"\\nPrediction: Fraudulent Transaction ðŸš©\")\n",
    "    else:\n",
    "        print(\"\\nPrediction: Legitimate Transaction âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "499ff7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ch Hassan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Random Forest model for fraud detection.\n",
      "\n",
      "Using hardcoded transaction data for prediction...\n",
      "\n",
      "Prediction: Legitimate Transaction âœ…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting testing interface.\n"
     ]
    }
   ],
   "source": [
    "## Run the CLI testing loop when script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Using {best_model_name} model for fraud detection.\")\n",
    "    \n",
    "    while True:\n",
    "        # Call prediction function with hardcoded input\n",
    "        predict_transaction(best_model, scaler, X.columns.tolist())\n",
    "        \n",
    "        # Ask if user wants to test another transaction\n",
    "        cont = input(\"Test another transaction? (y/n): \").strip().lower()\n",
    "        if cont != 'y':\n",
    "            print(\"Exiting testing interface.\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
